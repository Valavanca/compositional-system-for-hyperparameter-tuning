Introduction. Challenges and Problems.
======================================

The main goal of this thesis is to investigate portfolio of surrogate
models that can be used to improve applicability model-based
optimization methods to a verity of problems such as parameter tuning.
Surrogate model or models based optimization is a common approach for a
deal with expensive black-box function, but as far as the author is
aware, there is no published research where the influence of
heterogeneous portfolio of surrogate models was studied. The main target
problem is an expensive multi-objective problem but the developed
approach is also suitable for expensive single-objective optimization.
As black-box, we canâ€™t say what type of surface does the problem have.
That is why it should be customized in the optimization process. The
goal is to determine if the variability in extrapolation worth it

Multi-objective optimisation is an established parameter tuning
technique. It is especially suited to solve complex, multidisciplinary
design problems with an accent on system design.

When we talk about several objectives, the intention is to find good
compromises rather than a single solution as in global optimization.
Since the solution for multi-objective optimization problems gives the
appearance to a set of Pareto-optimal points, evolutionary optimization
algorithms are ideal for handling multi-objective optimization problems.

General optimization methods could be classified into derivative and
non-derivative methods. In this thesis focuses on non-derivative
methods, as they are more suitable for parameter tuning. Therefore, they
are also known as black-box methods and do not require any derivatives
of the objective function to calculate the optimum. Other benefits of
these methods are that they are more likely to find a global optimum.

Motivation
----------

The purpose of this study is to introduce new surrogate-design-criteria
for multi-objective hyperparameter optimization software.

Motivation Examples in tuning algorithms:

-   Local search: neighbourhoods, perturbations, tabu length, annealing

-   Tree search: pre-processing, data structures, branching heuristics,
    clause learning deletion

-   Genetic algorithms: population size, mating scheme, crossover,
    mutation rate, local improvement stages, hybridizations

-   Machine Learning: pre-processing, learning rate schedules

-   Deep learning (in addition): layers, dropout constants,
    pre-training, activations functions, units/layer, weight
    initialization

Objectives
----------

Black-box multi-objective problems given a finite number of function
evaluations

Research Questions
------------------

1.  RQ(Surrogate portfolio): How a surrogate portfolio influence on the
    optimization process?

2.  RQ(Composition model): How a compositional surrogate model influence
    on the optimization process?

3.  RQ(Sampling plan): Is the relation of the sampling plan with a
    surrogate validation can reduce samples set size?

In numerous test problems, compositional-surrogate finds comparable
solutions to standard MOEA (NSGA-II, MOEAD, MACO, NSPSO) doing
considerably fewer evaluations (300 vs 5000). Surrogate-based
optimization is recommended when a model is expensive to evaluate.
