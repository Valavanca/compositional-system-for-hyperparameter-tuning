Implementation. Development
===========================

separation of concerns

Managing Complex Execution Strategies

Dependencies
------------

Adapted to provide base implementation for stages in parameter tuning
with multi-objective

##### Pagmo2

A Python platform [@raw:francesco_biscani_2019] to perform parallel
computations of optimisation tasks (global and local) via the
asynchronous generalized island model. All test suites and basic
multi-objective solvers:

Realization of main MOEA:

-   NSGA2. Non-dominated Sorting Genetic Algorithm

-   MOEA/D. Multi Objective Evolutionary Algorithms by Decomposition
    (the DE variant)

-   MACO. Multi-objective Ant Colony Optimizer.

-   NSPSO.

Tests suits:

-   ZDT [@raw:ZitzlerDT00] is 6 different two-objective scalable problems
    all beginning from a combination of functions allowing, to measure
    the distance of any point to the Pareto front while creating
    problems.

-   WFG [@raw:WFGref] was conceived to exceed the functionalities of
    previously implemented test suites. In particular, non-separable
    problems, deceptive problems, truly degenerative problems and mixed
    shape Pareto front problems are thorougly covered, as well as
    scalable problems in both the number of objectives and variables.
    Also, problems with dependencies between position and distance
    related parameters are covered. In their paper the authors identify
    the need for nonseparable multimodal problems to test
    multi-objective optimization algorithms. Given this, they propose a
    set of 9 different scalable multi-objective unconstrained problems.

-   DTLZ [@raw:DebTLZ05]. All problems in this test suite are
    box-constrained continuous n-dimensional multi-objective problems,
    scalable in fitness dimension.

Portfolio with hypothesis
-------------------------

A set of models is defined that can form a partial or complete
hypothesis to describe the problem. Also during the increase of the
experiments may change the model that best describes the existing
problem As a result, there is variability for each problem and
configuration step at the same time. A set of hypotheses can solve this
problem but it takes longer time for cross validation.

Validate hypothesis
-------------------

The main task of learning algorithms is to be able to generalize to
unseen data. Surrogate model as learning model should generalize
examples to valid hypothesis. Since we cannot immediately check the
surrogate performance on new, incoming data, it is necessary to
sacrifice a small portion of the examples to check the quality of the
model on it. n case if surrogate model have enoughs score (pass metrics
threshold) we consider it valid and could be processed as subject for
inference(prediction).

### Sampling strategy

Oversampling and undersampling in data analysis. Alleviate imbalance in
the dataset. Imbalance in dataset is not always a problem, more so for
optimization tasks.

The main gain for models not to provide best accuracy on all search
space but provide possible optimum regions. Accuracy in prediction
optimal regions or points from there will direct the search in the right
direction.

Predictor variables can legitimately over- or under-sample. In this
case, provided a carefully check that the model assumptions seem valid.

for other set of parameters, and make a choice from more diverse pool of
models.
