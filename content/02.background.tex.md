Foundation
==========

Describe general objectives and there constraints

Parameter tuning
----------------

##### Single-obj optimization

Define an objective function:

-   Accuracy

-   Runtime

-   Latency

-   Energy

Optimization procedures:

-   Grid search

-   Random search

-   Heuristics

Bayesian methods differ from random or grid search in that they use past
evaluation results to choose the next values to evaluate. Limit
expensive evaluations of the objective function by choosing the next
input values based on those that have done well in the past.

Optimization cost:

-   Evaluation may be very expensive

-   Sampling budget

-   Possibly noisy

-   Feasibility constraints

-   Multi-objective

Ideally, we want a method that can explore the search space while also
limiting evaluations of poor hyperparameter choices.

Multi-objective optimization
----------------------------

\"Multi-objective optimization deals with such conflicting objectives.
It provides a mathematical framework to arrive at optimal design state
which accommodates the various criteria demanded by the application. The
process of optimizing systematically and simultaneously a collection of
objective functions are called multi-objective optimization
(MOO)[@raw:odugod2013]\". Thus, a central issue of MOO is the relationship
between the objective functions. These are usually modeled as
preferences of the decision maker.

Search or design space(Input space) -\> Objective space(Output space).
\[TODO\] Make plot Practical optimization problems usually involve
simultaneous optimization of multiple conflicting objectives with many
constraints(?).

Why is the Weighting Method Ineffective?\[Hirotaka Nakayama\] Namely, it
can not provide a solution among sunken parts of Pareto surface due to
"duality gap" for not convex cases. Even for convex cases, for example,
in linear cases, even if we want to get a point in the middle of line
segment between two vertices, we merely get a vertex of Pareto surface,
as long as the well known simplex method is used. This implies that
depending on the structure of problem, the linearly weighted sum can not
necessarily provide a solution as DM desires.

-   Quality and Effort tradeoff for multi-objective

-   Human in the loop: Composition technic as tools for domain expert

##### Conclusion

For optimization expensive black-box:

-   Scalable algorithms that convert multi-objective to single objective
    problem produce solution that not accurate enough(Scalarizing). Also
    this approach suitable for a limited type of problem.

-   Genetic algorithms. This approach is costly to perform and not
    appropriate for expensive problems.

Optimization gap in obtaining high quality, multi/single-obj solutions
in expensive to evaluate experiments. Experiments as a black box,
derivative-free. Reference to surrogate optimization.

Surrogate optimization
----------------------

Surrogate used to expedite search for global optimum. Global accuracy of
surrogate not a priority. Surrogate model is cheaper to evaluate than
the objective.

[@raw:EngSurMod]

##### Use cases

Example for each type of optimization. Justification solution.
Conclusion: Design gap in optimization/parameter tuning. Need to
indicate optimization workflow for expensive process/experiments. The
argument(s) why we need new architecture. Reference to composition
architecture.

Compositional architecture
--------------------------

##### Interfaces and Contracts

##### Reusable software

Problem that each optimization framework/library use inner interfaces.
It is necessary to define a standard that implements best practices for
extension libraries [@raw:buitinck2013api].

We introduce new Model-based line for parameter tuning.

Scope of work
-------------

Describe and implement workflow for multi-objective parameter tuning of
derivative free, black-box system. Parameter estimation is costly. The
proposed solutions are also suitable for single-criteria optimization.
Problem Setting.

Goal:

1.  Globally optimize an objective function(s) that is expensive to
    evaluate. Single/Multi-objective parameter tuning

2.  Scalability in optimization objective. Simultaneously. Gradient-free
    evaluation.

3.  Components reuse. Extensibility with other frameworks.

Problem:

1.  A large number of the target black-box evaluations.

2.  Interfaces not unify.

3.  Code duplication.

Solution:

1.  Compositional architecture.

2.  Surrogate optimization.
