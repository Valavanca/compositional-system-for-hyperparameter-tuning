Background {#sec:background}
==========

##### Intent:

General background information needed to follow the terms and methods
used in this thesis.

Structure:

1. Parameter tuning

:   Parameter tuning of a black-box

    1.  $f(Parameter) = Objective$

    2.  Goal is optimize $f$

    3.  Problem: Optimization of multiple objectives

2. Multi-objective optimization

:   General definition. Pareto front and None-dominated solution

    1.  What is a multi-objective solution?

    2.  How to compare solutions? $\rightarrow$ Types of metrics

    3.  How to solve? $\rightarrow$ Scalarizing, MOEA, Random

    4.  Problem: Reduce evaluations $\rightarrow$ Surrogate
        optimization, MBMO

3. Surrogate optimization

:   Approach for reducing evaluation count

    1.  Intro. Cons and Pons

    2.  Types of a surrogate model in a MO-problem (Model of
        scalarization, MO-model, Replicated MO-model, Compositional
        MO-model). Taxonomy

    3.  Surrogate assistance for MO parameter tuning $\rightarrow$
        Reusable/scalable components for optimization $\rightarrow$
        Problem: Scalability of a surrogate model. \[RQ3 \[RQ3\]\]

    4.  Surrogate model is domain-specific $\rightarrow$ Analyze
        multiple surrogates $\rightarrow$ Surrogate portfolio \[RQ1
        \[RQ1\]\]

    5.  Sampling plan. Build a surrogate model. Quality of prediction
        depends on the accuracy of a surrogate model $\rightarrow$
        Accuracy depends on a sample size $\rightarrow$ Sample size
        depends on surface type $\rightarrow$ Problem: Sample size is
        static. \[RQ2 \[RQ2\]\]

    6.  Surrogates and MOEA are hard scalable \[RQ3 \[RQ3\]\]

4. Scope of work

:   Starting point of thesis

    1.  Problem: Expensive black-box with multiple objectives

    2.  Constraint: Evaluation budget

    3.  Goal: Set of MO solutions closed to Pareto-front $\rightarrow$
        1.$Max$ Hypervolume, 2.$Min$ Points-Space, 3.$Max$ % of
        None-Dominated points

    4.  Solution approach: Surrogate model(s) with MOEA

##### Intro

This chapter presents general background information needed to follow
the terms and methods used in this thesis. What is parameter tuning? Why
is multi-objective important? Why we cannot use the standard
multi-objective approach in real-life problem/parameter tuning task, and
why model-based or surrogate optimization is the best solution?

In typical software design, engineers carefully convert overall models
into domain-specific tools. In this approach, designers codify the
current understanding of the problem into the parameters.

Parameter tuning
----------------

This article assumes that parameter tuning is a subset problem of
general, global optimizations. It also means that we consider some
fitness function $f$ that converts the parameter vector to output
objectives. Note that the term “real evaluation” or “black-box
evaluation” as a synonym for the fitness function $f$.

The goal of parameter tuning as an optimization task lay on a fast
iterative search with improvements in each objective dimension. The term
“fast” means that the convergence to global optimum is achieved with the
least real evaluations and shorter time frame.

We consider fitness function $f$ as a black-box with parameter and
objective space. Parameter space has structure and could consist of
continuous and categorical dimensions. Sometimes, some combinations of
parameter settings are forbidden. Each point from parameter space leads
to some point in objective space. Configurations often yield
qualitatively different behavior. Objective space also could be
described as usual objectives as accuracy, runtime, latency,
performance, error rate, energy. Each objective should gain the best
possible value and profit in the system’s tradeoff.

Optimization technics:

-   Grid search vs Random search

-   Heuristics and Metaheuristic. (Simulated annealing, Evolutionary
    algorithm) These methods aim at generating approximately optimal
    solutions in a single run. It also could operate with sets of
    solutions, being outcomes of multiple objectives.

-   Sequential design (Bayesian optimization, Evolutionary algorithm)
    Bayesian methods differ from random or grid search in that they use
    past evaluation results to extrapolate and choose the following
    values to evaluate. Limit expensive evaluations of the objective
    function by choosing the following input values based on those that
    have done well in the past.

Optimization cost of black-box:

-   Evaluation may be very expensive

-   Sampling budget is unknown

-   Possibly noisy objectives

-   Feasibility constraints

-   Multi-objectivity

Ideally, we want a method that can explore the search space while also
limiting evaluations of hyperparameter choices. One way to clarify the
task of understanding the space of possible solutions is to focus on the
non-dominated frontier or Pareto-front, the subset of solutions that are
not worse than any other but better on at least one goal. The difficulty
here is that even the Pareto frontier can be too large to understand.

Multi-objective optimization
----------------------------

Common optimization problems require the simultaneous optimization of
multiple, usually contradictive objectives. Multi-objective optimization
deals with such conflicting objectives. It provides a mathematical
algorithm to arrive at an optimal design state which accommodates the
various criteria demanded by the application. The process of optimizing
systematically and simultaneously a collection of objective functions
are called multi-objective optimization [@raw:odugod2013]. The solution to
such problems is a family of points that placing on a Pareto front.
Awareness of the Pareto front allows visualizing appropriate decisions
in terms of performance for each objective. For a multi-objective
problem, we consider “solution” as points from parameter space that lead
to non-dominated results in objective space. This set of points
approximates real Pareto-front. Improving “solution” means that sets of
points match better with real Pareto-front.

There are two types of multi-objective solution:

-   Single-point

-   Multi-point

### Metrics for multi-objective solution

In single-objective optimization, the quality of a given solution is
trivial to quantify. When we consider a solution of a multi-objective
problem as multi-point aproximation, comparison of these points is also
a multi-objective task. The question of metrics for evalution is
essential for the comparison of algorithms or select a point from
approximations.

According to [@raw:ZitzlerDT00], a Pareto front approximation should satisfy
the following:

-   The distance between the Pareto front and its approximation should
    be minimized.

-   A heigh distribution of the non-dominated points is desirable.

-   The range of the approximated front should be maximized, i.e., for
    each objective, a wide range of values should be covered by the
    non-dominated points.

Metrics for performance indicators partitioned into four groups
according to their properties [@raw:Audet2018PerformanceII] are cardinality,
convergence, distribution and spread.

Base on the right metrics, the general multi-objective algorithm keeps
making progress toward the Pareto front in the objective function space.

The goal of multi-objective optimizing is to obtain an approximation
solution set to the reference Pareto front, including the following
subgoals:

-   All solution set are as close as possible to the Pareto front

-   All solution set are as diverse as possible in the objective space

-   The proportion of solutions set to the evaluated set as large as
    possible. Evaluate as few solutions as feasible.

Also, distribution and spread indicators is considered in this work.
According to [@raw:CustodioMVV11], “the spread metrics try to measure the
extents of the spread achieved in a computed Pareto front
approximation.” They are not useful to evaluate the convergence of an
algorithm, or at comparing algorithms. They only make sense when the
Pareto set is composed of several solutions. For multi-objective
optimization, an algorithm should provide a set of solutions that
realize the optimal trade-offs between the considered optimization
objectives. Therefore, the performance comparison of MOO algorithms is
based on their Pareto sets. In this study, four popular metrics are used
to quantify the performance of the algorithms.

-   **Hypervolume (HV).**[@raw:Zitzler2000ComparisonOM] *Convergence and
    distribution indicator.* This metric represents the volume of the
    objective space that is covered by the individuals of non-dominated
    solutions set solutions that belong to a Pareto front. Two points
    delimit the volume: one point is the reference point that is defined
    as the worst solution inside the objective space, and a second
    optimal point (pseudo-optimal) that is calculated by the proposed
    solution method. Determining the hypervolume indicator is a
    computationally expensive task. Even in case of a reasonably small
    dimension and low number of points, there are currently no known
    algorithms that can yield the results fast enough for use in most
    multiple-objective optimizers.

-   **Non-dominated Ratio (NDR).** *Cardinality.* This metric employs
    the non-dominated count of a solution set divided by the total size
    of solution set. Higher values are preferred to lower ones.

-   **Spacing [@raw:Schott1995FaultTD].** *Distribution and spread.*
    Describe the distribution of Pareto points. Fewer space metrics
    means better coverage of objectives values range.

-   **$\Upsilon$-metric (p-distance)**[@raw:Martens13] *Convergence* This
    metric is the average distance of any set of points to the Pareto
    front. The lower the $\Upsilon (P)$, the closer the solutions of P
    are to solutions of the Pareto-front.
    $\Upsilon(P) = \frac{1}{|P|}\sum_{x\in P}g(x)-g(x^*)$

### Solving methods

In this thesis, under the Pareto-optimal front mean an ideal solution to
the problem. None-dominated points it is a subset of some feasible
points that is none dominated. All points from Pareto-frontier are
none-dominated, but not all none-dominated points are Pareto-optimal.

![The Pareto-optimal solution is near-optimal to real Pareto frontier,
while none-dominance is a subset of point in any group of
points.[]{data-label="fig:dominated"}](content/images/dominated)

#### Scalarizing

The Scalarizing approach is a popular technique for creating a
single-objective *parameterized* problem with the composite criteria
from multiple objectives. It folows then single-objective optimization
techniques could be applied to this composite function to obtain a
single optimal solution. The weighted-sum methods it is a well-known
type of scalarizing technic. This approach concatenates the objectives
into one criterion by using weighted sum factors. There are difficulties
in selecting proper weights, especially when there is no correlation in
prior knowledge among objectives.

Furthermore, uniform distribution points in parameter space do not
generate uniform distribution points on objective space. This means that
complete approximating of Pareto-front even with multiple optimization
rounds, is exhausting. Some scalarizing technics try to improve the
exploration of parameter space by assigning more “intelligence”
aggregation to the objectives. Such solutions may be fragile. They
change dramatically in a modification of algorithm parameters.Moreover,
the weighting method can not provide a solution among underparts of the
Pareto surface due to the “duality gap” for not convex cases. Also, some
of scalarizing algorithms are very sensitive to the number of objectives
and an analysis of the objecive surface with different scalarizing
techniques might be helpful in the optimization for solving expensive
MOPs [@raw:ChughScal2019].

#### Multi-Objective Evolutionary Algorithms

Generating the Pareto-optimal set often impracticable and can be
computationally expensive. Accordingly, many stochastic search
strategies have been developed, such as evolutionary algorithms, tabu
search, simulated annealing, and ant colony optimization. That
algorithms regularly do not ensure to find ideal trade-offs but try to
gain a good approximation.

The evolutionary algorithm forms a class of heuristic search methods
that simulate the process of natural evolution. Using simplifications,
EA is subsequently determined by the two basic principles: selection and
variation [@raw:TutMOEABrockhoff]. While selection reflects the competition
for reproduction and resources among individuals, the other principle,
variation, imitates the natural ability to produce new individuals
through recombination and mutation. Evolutionary algorithm has several
characteristics that are desirable for problems including multiple
conflicting objectives, and large and complicated search spaces.
Evolutionary optimizers explore populations of candidate solutions in
each generation, some mutator can make changes to the current
population. A select operator then picks the best mutants which are then
combined in some way to become generation i+1. However, EA still need
many evaluations of the “black box” system to solve a common
multi-objective problem. This is further difficult by the fact that many
such problems are very expensive. This makes EAs unfeasible for costly
and Multy-objective problem.

##### Conclusion on algorithms

While other methods also exist, in this thesis we will focus on
improving approaches with Evolutionary Algorithms for the
Multy-objective optimizations. A good solution is the integration of the
surrogate model which extrapolate and approximate the fitness landscape
from samples. Multi-objective Evolutionary Algorithms (MOEAs) use this
surrogate model as a target for optimization. Assumed that solution from
surrogate nearby to a global optimum.

Motivation for Surrogates

For optimization expensive black-box:

-   Scalable algorithms that convert multi-objective to single objective
    problem produce solution that not accurate enough(Scalarizing). Also
    this approach suitable for a limited type of problem. Also, there
    are a lot important parameters that significant influence on
    algorithm performance.

-   Genetic algorithms. This approach is costly to perform and not
    appropriate for expensive problems.

Optimization gap in obtaining high quality, multi/single-obj solutions
in expensive to evaluate experiments. Experiments as a black box,
derivative-free. Reference to surrogate optimization.

Surrogate optimization
----------------------

The potential for applying surrogate is laid in the fast evaluation of
the surrogate model. This advantage should outperform disadvantage in
time required to build this surrogate model. In classical model-based
optimization, single surrogate-model is used that provides a hypothesis
on the relation between parameter and objective space. There is a lot
type of models that can do it but out and away fewer models that can
manage multidimensionality objective space.

A surrogate model is either selected randomly or due to its popularity
in the associated domain area. However, there are still some open
challenges related to the combination of meta-models, such as the
definition of a criterion for choosing several models or how to use
simultaneously different surrogate models can. Besides, there are no
guidelines for using heterogeneous compositional models for different
objective functions [@raw:SoftSurvey].

[@raw:EngSurMod]

To dealing with expensive optimization problems more quickly, we can use
surrogate models in the optimization process to approximate the
objective functions. Approximation of the solution is faster than the
whole optimization process can be accelerated. Although the extra time
indeed needed to build and update the surrogate models during the
optimization process. In the case of pre-selecting the promising
individuals, the surrogate model is used to find the likely or drop the
low-quality individuals even before they are exactly evaluated, thus
reducing the number of exact evaluations.

In the literature, the term surrogate or model-based optimization is
used where, during the optimization processes, some solutions are not
evaluated with the original function, but are approximated using a model
of this function. Some of the most commonly used methods are the
Response Surface Method [@raw:ResponseSurface], Radial Basis Function
[@raw:Rasmussen2004], Neural Network, Kriging [@raw:Woodard00], and Gaussian
Process Modeling [@raw:RasmussenN10; @raw:RasmussenW06]. These methods usually
approximate a single objective. As a result, for a multi-objective
problem, a method is replicated on each criterion
[@raw:Knowles06; @raw:nardi2019practical].

#### Multi-objective parameter tuning

Classification of parameter tuning as MBMO approaches based on the
workflow of sequential model-based optimization. First is the initial
sampling plan with parameters that already evaluated. As an initial
sampling plan or design-of-experimnet(DOE), can use technics as Latin
Hypercube Sampling (LHS), Sobol sampling, or alternative is random
sampling.

![Phases and tasks within a generalized multi-objective parameter
tuning[]{data-label="fig:mo_param_tuning"}](content/images/tax_mb_tuning.png){width="\textwidth"}

For extrapolate samples, there are two approaches established. 1) Direct
build surrogates on scalarize objectives and produce a surrogate model
as aggregation. In this case, the multi-objective problem transforms
into a single-objective one. 2) Keep original dimensionality of the
problem, and apply one or several models to hold and infer in objective
space. The optimization search represents an exploration of the optimal
point(s) with a surrogate model. This step produces candidates for a
real evaluation. In the second stage, sorting and selection are carried
out. The required number of points is allowed to estimate and update the
sample set. The advantage of possible prediction several parameters
instead of a single one is not only used for improving the exploration
of the parameter space, but also for parallelizing evaluation.
Optimization iterations continue until the stop condition is satisfied.

##### Compositional surrogates

The variability and extensibility are essential for configurable
parameter tuning, such as a software product line. The optimization
round is monolithic and context dependant. As shown in Figure
\[fig:mo\_param\_tuning\], the potential to reuse components in a
workflow is huge. The same single-objective models can be equally
applied to various types of problems in multi-/single-objective
optimization. The optimization algorithm weakly depends on the type of
simulation. Consider improving parameter tuning to multiply criteria on
the fly by dynamically duplicate surrogate model or even create several
variants surrogate hypothesis.

### Domain-specific problem

Intending to find the best solution with less effort, surrogate models
are domain-specific. It could be an interpreter as a Non-free lunch
theorem in model-based optimization. If we extend this argument, then
the same optimization problem in different parameter tuning iteration
could be interpreted as another optimization problem. This means that to
reduce effort and increase the convergence of an algorithm, we should
change the surrogate model depend on how much samples do we have. As one
would expect, no approximation method is universal. This leads us to use
a portfolio with surrogate models. On each optimization, iteration tries
several models and selects thous who have the best accuracy. As a
negative consequence, the model fitting additional introduces an
additional overhead into the optimization.

### Build the surrogate model(s). Sampling plan

Initial samples should provide maxim information to build a valuable
model. With more samples, in case of proper fitting, the exact model is
obtained, and in optimization, is reached better results. On the other
hand, the initial sample size may be too big, and this is wasting
samples. Furthermore, samples maybe not enough, and better select points
from initial design than to be guided by an incorrect model.

Given the type of objective surface, the expert can assume how much
sample points are required to approximate the objective(s). For simple
dependencies or more complex surfaces, the difference can be hundreds or
thousands of points. In the case of the optimization black-box, this
information is unknown. Therefore a dynamic sampling plan should be
implemented to reduce the number of estimations and improve the
convergence of the optimization algorithm.

##### Discussion

Example of each type of optimization. Justification solution.
Conclusion: Design gap in optimization/parameter tuning. Need to
indicate optimization workflow for expensive process/experiments. The
argument(s) why we need a new architecture. Reference to composition
architecture.

Scope of work
-------------

Surrogate based optimization has proven effective in many aspects of
engineering and in applications where data is “expensive”, or difficult,
to evaluate.

Describe and implement workflow for expensive multi-objective parameter
tuning of the derivative-free, black-box system. The proposed solutions
are backword compatable for single-criteria optimization. Thre are
follows research scope in this thesis:

-   Single and compositional surrogate models for objectives

-   The main optimization search technique selected a multi-objective
    evolutionary algorithm.

-   Consider metrics for solution: hypervolume, space, and non-dominated
    ratio.

-   Dynamic initial sampling

Goal:

1.  Globally optimize an objective multi-objective function that is
    expensive to evaluate.

2.  Scalable multi-objective optimization

3.  Components reuse. Extensibility with other frameworks

Problem:

1.  A large number of the target black-box evaluations

2.  Surrogate selection

3.  Code duplication

Solution:

1.  Surrogate portfolio

2.  Compositional surrogate

3.  Adaptive sampling plan
