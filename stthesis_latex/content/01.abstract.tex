\chapter{Introduction. Challenges and Problems.}

The main goal of this thesis is to investigate portfolio of surrogate models that can be used to improve applicability model-based optimization methods to a verity of problems such as parameter tuning. Surrogate model or models based optimization is a common approach for a deal with expensive black-box function, but as far as the author is aware, there is no published research where the influence of heterogeneous portfolio of surrogate models was studied. The main target problem is an expensive multi-objective problem but the developed approach is also suitable for expensive single-objective optimization.
As black-box, we can't say what type of surface does the problem have. That is why it should be customized in the optimization process. The goal is to determine if the variability in extrapolation worth it



Multi-objective optimisation is an established parameter tuning technique. It is especially suited to solve complex, multidisciplinary design problems with an accent on system design.

When we talk about several objectives, the intention is to find good compromises rather than a single solution as in global optimization.
Since the solution for multi-objective optimization problems gives the appearance to a set of Pareto-optimal points, evolutionary optimization algorithms are ideal for handling multi-objective optimization problems.

General optimization methods could be classified into derivative and non-derivative methods. In this thesis focuses on non-derivative methods, as they are more suitable for parameter tuning. Therefore, they are also known as black-box methods and do not require any derivatives of the objective function to calculate the optimum.  Other benefits of these methods are that they are more likely to find a global optimum. 

\section{Motivation}
    The purpose of this study is to introduce new surrogate-design-criteria for multi-objective hyperparameter optimization software.

    Motivation Examples in tuning algorithms:
    \begin{itemize}
        \item Local search: neighbourhoods, perturbations, tabu length, annealing
        \item Tree search: pre-processing, data structures, branching heuristics, clause learning deletion
        \item Genetic algorithms: population size, mating scheme, crossover, mutation rate, local improvement stages, hybridizations
        \item Machine Learning: pre-processing, learning rate schedules
        \item Deep learning (in addition): layers, dropout constants, pre-training, activations functions, units/layer, weight initialization  
    \end{itemize}

\section{Objectives}
    Black-box multi-objective problems given a finite number of function evaluations

\section{Research Questions}
\begin{enumerate}
    \item RQ(Surrogate portfolio): How a surrogate portfolio influence on the optimization process?
    \item RQ(Composition model): How a compositional surrogate model influence on the optimization process?
    \item RQ(Sampling plan): Is the relation of the sampling plan with a surrogate validation can reduce samples set size?
\end{enumerate}

In numerous test problems, compositional-surrogate finds comparable solutions to standard MOEA (NSGA-II, MOEAD, MACO, NSPSO) doing considerably fewer evaluations (300 vs 5000). 
Surrogate-based optimization is recommended when a model is expensive to evaluate.

% \section{Solution}

% \section{Organization of the Thesis}
