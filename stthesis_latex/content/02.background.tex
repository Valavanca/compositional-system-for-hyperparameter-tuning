\chapter{Background}\label{sec:background}

    \begin{blockquote}
        \paragraph{Intent:} General background information needed to follow the terms and methods used in this thesis. 
                
        Structure:
        \begin{description}
            \item[1. Parameter tuning] Parameter tuning of a black-box
                \begin{enumerate}
                    \item $f(Parameter) = Objective$ 
                    \item Goal is optimize $f$
                    \item Problem: Optimization of multiple objectives
                \end{enumerate}
            \item[2. Multi-objective optimization] General definition. Pareto front and None-dominated solution
                \begin{enumerate}
                    \item What is a multi-objective solution?
                    \item How to compare solutions? $\rightarrow$ Types of metrics
                    \item How to solve? $\rightarrow$ Scalarizing, MOEA, Random
                    \item Problem: Reduce evaluations $\rightarrow$ Surrogate optimization, MBMO
                \end{enumerate}
            \item[3. Surrogate optimization] Approach for reducing evaluation count
                \begin{enumerate}
                    \item Intro. Cons and Pons
                    \item Types of a surrogate model in a MO-problem (Model of scalarization, MO-model, Replicated MO-model, Compositional MO-model). Taxonomy
                    \item Surrogate assistance for MO parameter tuning $\rightarrow$ Reusable/scalable components for optimization $\rightarrow$ Problem: Scalability of a surrogate model. [RQ3 \ref{RQ3}]                   
                    \item Surrogate model is domain-specific $\rightarrow$ Analyze multiple surrogates $\rightarrow$ Surrogate portfolio [RQ1 \ref{RQ1}]
                    \item Sampling plan. Build a surrogate model. Quality of prediction depends on the accuracy of a surrogate model  $\rightarrow$ Accuracy depends on a sample size $\rightarrow$ Sample size depends on surface type $\rightarrow$ Problem: Sample size is static. [RQ2 \ref{RQ2}]
                    \item Surrogates and MOEA are hard scalable [RQ3 \ref{RQ3}]
                \end{enumerate}
            \item[4. Scope of work] Starting point of thesis
                \begin{enumerate}
                    \item Problem: Expensive black-box with multiple objectives
                    \item Constraint: Evaluation budget
                    \item Goal: Set of MO solutions closed to Pareto-front $\rightarrow$ 1.$Max$ Hypervolume, 2.$Min$ Points-Space, 3.$Max$ \% of None-Dominated points 
                    \item Solution approach: Surrogate model(s) with MOEA
                \end{enumerate}
        \end{description}
    \end{blockquote}

    \paragraph{Intro}
    This chapter presents general background information needed to follow the terms and methods used in this thesis. What is parameter tuning? Why is multi-objective important? Why we cannot use the standard multi-objective approach in real-life problem/parameter tuning task, and why model-based or surrogate optimization is the best solution?

    In typical software design, engineers carefully convert overall models into domain-specific tools. In this approach, designers codify the current understanding of the problem into the parameters.

    % --------------------------------------------------------------------------------------------
    % ------------------------------------------------        Parameter tuning
    % --------------------------------------------------------------------------------------------
    \section{Parameter tuning}
        This article assumes that parameter tuning is a subset problem of general, global optimizations. It also means that we consider some fitness function $f$ that converts the parameter vector to output objectives.  Note that the term "real evaluation" or "black-box evaluation" as a synonym for the fitness function $f$. 
        
        The goal of parameter tuning as an optimization task lay on a fast iterative search with improvements in each objective dimension. The term "fast" means that the convergence to global optimum is achieved with the least real evaluations and shorter time frame.

        We consider fitness function $f$ as a black-box with parameter and objective space. Parameter space has structure and could consist of continuous and categorical dimensions. Sometimes, some combinations of parameter settings are forbidden. Each point from parameter space leads to some point in objective space. Configurations often yield qualitatively different behavior.
        Objective space also could be described as usual objectives as accuracy, runtime, latency, performance, error rate, energy. Each objective should gain the best possible value and profit in the system's tradeoff.

        Optimization technics:
        \begin{itemize}
            \item Grid search vs Random search
            \item Heuristics and Metaheuristic. (Simulated annealing, Evolutionary algorithm) These methods aim at generating approximately optimal solutions in a single run. It also could operate with sets of solutions, being outcomes of multiple objectives.
            \item Sequential design (Bayesian optimization, Evolutionary algorithm) Bayesian methods differ from random or grid search in that they use past evaluation results to extrapolate and choose the following values to evaluate. Limit expensive evaluations of the objective function by choosing the following input values based on those that have done well in the past.
        \end{itemize}

        Optimization cost of black-box:
        \begin{itemize}
            \item Evaluation may be very expensive
            \item Sampling budget is unknown
            \item Possibly noisy objectives
            \item Feasibility constraints
            \item Multi-objectivity
        \end{itemize}

        Ideally, we want a method that can explore the search space while also limiting evaluations of hyperparameter choices. 
        One way to clarify the task of understanding the space of possible solutions is to focus on the non-dominated frontier or Pareto-front, the subset of solutions that are not worse than any other but better on at least one goal. The difficulty here is that even the Pareto frontier can be too large to understand. 
    

    % --------------------------------------------------------------------------------------------
    % ------------------------------------------------        Multi-objective       -------------
    % --------------------------------------------------------------------------------------------
    \section{Multi-objective optimization}
        Common optimization problems require the simultaneous optimization of multiple, usually contradictive objectives.         Multi-objective optimization deals with such conflicting objectives. It provides a mathematical algorithm to arrive at an optimal design state which accommodates the various criteria demanded by the application. The process of optimizing systematically and simultaneously a collection of objective functions are called multi-objective optimization \cite{odugod2013}. The solution to such problems is a family of points that placing on a Pareto front. Awareness of the Pareto front allows visualizing appropriate decisions in terms of performance for each objective. For a multi-objective problem, we consider "solution" as points from parameter space that lead to non-dominated results in objective space. This set of points approximates real Pareto-front. Improving "solution" means that sets of points match better with real Pareto-front.

        There are two types of multi-objective solution:
        \begin{itemize}
            \item Single-point
            \item Multi-point
        \end{itemize}

    % ------------------------------------------------        Metrics       -------------
        \subsection{Metrics for multi-objective solution}

        In single-objective optimization, the quality of a given solution is trivial to quantify. When we consider a solution of a multi-objective problem as multi-point aproximation, comparison of these points is also a multi-objective task.
        The question of metrics for evalution is essential for the comparison of algorithms or select a point from approximations.

        According to \cite{ZitzlerDT00}, a Pareto front approximation should satisfy the following:
        \begin{itemize}
            \item The distance between the Pareto front and its approximation should be minimized.
            \item A heigh distribution of the non-dominated points is desirable.
            \item The range of the approximated front should be maximized, i.e., for each objective, a wide range of values should be covered by the non-dominated points.
        \end{itemize}

        Metrics for performance indicators partitioned into four groups according to their properties \cite{Audet2018PerformanceII} are cardinality, convergence, distribution and spread.

        Base on the right metrics, the general multi-objective algorithm keeps making progress toward the Pareto front in the objective function space.

        The goal of multi-objective optimizing is to obtain an approximation solution set to the reference Pareto front, including the following subgoals:
        \begin{itemize}
            \item All solution set are as close as possible to the Pareto front
            \item All solution set are as diverse as possible in the objective space
            \item The proportion of solutions set to the evaluated set as large as possible. Evaluate as few solutions as feasible.
        \end{itemize}

        Also, distribution and spread indicators is considered in this work. According to \cite{CustodioMVV11}, “the spread metrics try to measure the extents of the spread achieved in a computed Pareto front approximation.” They are not useful to evaluate the convergence of an algorithm, or at comparing algorithms. They only make sense when the Pareto set is composed of several solutions.
        % ! spread indicators not for convergence

        For multi-objective optimization, an algorithm should provide a set of solutions that realize the optimal trade-offs between the considered optimization objectives. Therefore, the performance comparison of MOO algorithms is based on their Pareto sets. In this study, four popular metrics are used to quantify the performance of the algorithms.
        \begin{itemize}
            \item \textbf{Hypervolume (HV).}\cite{Zitzler2000ComparisonOM} \textit{Convergence and distribution indicator.}
            This metric represents the volume of the objective space that is covered by the individuals of non-dominated solutions set solutions that belong to a Pareto front. Two points delimit the volume: one point is the reference point that is defined as the worst solution inside the objective space, and a second optimal point (pseudo-optimal) that is calculated by the proposed solution method. Determining the hypervolume indicator is a computationally expensive task. Even in case of a reasonably small dimension and low number of points, there are currently no known algorithms that can yield the results fast enough for use in most multiple-objective optimizers.
            \item \textbf{Non-dominated Ratio (NDR).} \textit{Cardinality.} This metric employs the non-dominated count of a solution set divided by the total size of solution set. Higher values are preferred to lower ones.
            \item \textbf{Spacing \cite{Schott1995FaultTD}.} \textit{Distribution and spread.} Describe the distribution of Pareto points. Fewer space metrics means better coverage of objectives values range. 
            \item \textbf{$\Upsilon$-metric (p-distance)}\cite{Martens13} \textit{Convergence} This metric is the average distance of any set of points to the Pareto front. The lower the $\Upsilon (P)$, the closer the solutions of P are to solutions of the Pareto-front. $\Upsilon(P) = \frac{1}{|P|}\sum_{x\in P}g(x)-g(x^*)$
            
        \end{itemize}
 
    % ------------------------------------------------        Solving methods       -------------
        \subsection{Solving methods}
        In this thesis, under the Pareto-optimal front mean an ideal solution to the problem. None-dominated points it is a subset of some feasible points that is none dominated. All points from Pareto-frontier are none-dominated, but not all none-dominated points are Pareto-optimal.

                % ==== dominated
                \begin{figure}
                    \centering
                    \includegraphics{content/images/dominated}
                    \caption[Pareto-optimal points vs. none dominated]{The Pareto-optimal solution is near-optimal to real Pareto frontier, while none-dominance is a subset of point in any group of points.}
                    \label{fig:dominated}
                \end{figure}
        
            % ----------------      Scalarizing       
            \subsubsection{Scalarizing}
                The Scalarizing approach is a popular technique for creating a single-objective \textit{parameterized} problem with the composite criteria from multiple objectives. It folows then single-objective optimization techniques could be applied to this composite function to obtain a single optimal solution. The weighted-sum methods it is a well-known type of scalarizing technic. This approach concatenates the objectives into one criterion by using weighted sum factors. There are difficulties in selecting proper weights, especially when there is no correlation in prior knowledge among objectives.  

                Furthermore, uniform distribution points in parameter space do not generate uniform distribution points on objective space. This means that complete approximating of Pareto-front even with multiple optimization rounds, is exhausting.
                Some scalarizing technics try to improve the exploration of parameter space by assigning more "intelligence" aggregation to the objectives. Such solutions may be fragile. They change dramatically in a modification of algorithm parameters.Moreover, the weighting method can not provide a solution among underparts of the Pareto surface due to the “duality gap” for not convex cases.                 Also, some of scalarizing algorithms are very sensitive to the number of objectives and an analysis of the objecive surface with different scalarizing techniques might be helpful in the optimization for solving expensive MOPs \cite{ChughScal2019}.

                % For example, if we want to reach the point in the middle of two other points in Pareto frontier, we hardly get a peek of the Pareto surface, as long as the well-known simplex method is used. This implies that depending on the structure of the problem. The linearly weighted sum can not necessarily provide a solution as DM desires. \cite{Nakayama05}. Moreover, the weighting method can not provide a solution among underparts of the Pareto surface due to the “duality gap” for not convex cases. 

            % --------------------      MOEA
            \subsubsection{Multi-Objective Evolutionary Algorithms}
                Generating the Pareto-optimal set often impracticable and can be computationally expensive. Accordingly, many stochastic search strategies have been developed, such as evolutionary algorithms, tabu search, simulated annealing, and ant colony optimization. That algorithms regularly do not ensure to find ideal trade-offs but try to gain a good approximation.
 
                The evolutionary algorithm forms a class of heuristic search methods that simulate the process of natural evolution. Using simplifications,  EA is subsequently determined by the two basic principles: selection and variation \cite{TutMOEABrockhoff}. While selection reflects the competition for reproduction and resources among individuals, the other principle, variation, imitates the natural ability to produce new individuals through recombination and mutation. Evolutionary algorithm has several characteristics that are desirable for problems including multiple conflicting objectives, and large and complicated search spaces. Evolutionary optimizers explore populations of candidate solutions in each generation, some mutator can make changes to the current population. A select operator then picks the best mutants which are then combined in some way to become generation i+1. However, EA still need many evaluations of the "black box" system to solve a common multi-objective problem. This is further difficult by the fact that many such problems are very expensive. This makes EAs unfeasible for costly and Multy-objective problem. 


        % ------------------------------------------------        Conclusion       -------------
        \paragraph{Conclusion on algorithms}

            While other methods also exist, in this thesis we will focus on improving approaches with Evolutionary Algorithms for the Multy-objective optimizations. A good solution is the integration of the surrogate model which extrapolate and approximate the fitness landscape from samples. Multi-objective Evolutionary Algorithms (MOEAs) use this surrogate model as a target for optimization. Assumed that solution from surrogate nearby to a global optimum.

            Motivation for Surrogates

            For optimization expensive black-box:
            \begin{itemize}
                \item Scalable algorithms that convert multi-objective to single objective problem produce solution that not accurate enough(Scalarizing). Also this approach suitable for a limited type of problem. Also, there are a lot important parameters that significant influence on algorithm performance.
                \item Genetic algorithms. This approach is costly to perform and not appropriate for expensive problems.
            \end{itemize}
            Optimization gap in obtaining high quality, multi/single-obj solutions in expensive to evaluate experiments.
            Experiments as a black box, derivative-free. Reference to surrogate optimization.


    % --------------------------------------------------------------------------------------------
    % ------------------------------------------        Surrogate optimization       -------------
    % --------------------------------------------------------------------------------------------
    \section{Surrogate optimization} 

        The potential for applying surrogate is laid in the fast evaluation of the surrogate model. This advantage should outperform disadvantage in time required to build this surrogate model. In classical model-based optimization, single surrogate-model is used that provides a hypothesis on the relation between parameter and objective space. There is a lot type of models that can do it but out and away fewer models that can manage multidimensionality objective space.

        A surrogate model is either selected randomly or due to its popularity in the associated domain area.  However, there are still some open challenges related to the combination of meta-models, such as the definition of a criterion for choosing several models or how to use simultaneously different surrogate models can. Besides, there are no guidelines for using heterogeneous compositional models for different objective functions \cite{SoftSurvey}.

        \cite{EngSurMod} 

        To dealing with expensive optimization problems more quickly, we can use surrogate models in the optimization process to approximate the objective functions. Approximation of the solution is faster than the whole optimization process can be accelerated. Although the extra time indeed needed to build and update the surrogate models during the optimization process. 
        In the case of pre-selecting the promising individuals, the surrogate model is used to find the likely or drop the low-quality individuals even before they are exactly evaluated, thus reducing the number of exact evaluations.

        In the literature, the term surrogate or model-based optimization is used where, during the optimization processes, some solutions are not evaluated with the original function, but are approximated using a model of this function. Some of the most commonly used methods are the Response Surface Method \cite{ResponseSurface}, Radial Basis Function \cite{Rasmussen2004}, Neural Network, Kriging \cite{Woodard00}, and Gaussian Process Modeling \cite{RasmussenN10, RasmussenW06}. These methods usually approximate a single objective. As a result, for a multi-objective problem, a method is replicated on each criterion \cite{Knowles06, nardi2019practical}.

        % -------------------------------------------------------------------------------------------------
        % ------------------------------------------------        MO in Parameter tuning       -------------
        \subsubsection{Multi-objective parameter tuning}

            Classification of parameter tuning as MBMO approaches based on the workflow of sequential model-based optimization. First is the initial sampling plan with parameters that already evaluated. As an initial sampling plan or design-of-experimnet(DOE), can use technics as Latin Hypercube Sampling (LHS), Sobol sampling, or alternative is random sampling.
            
            % ===  Phases and tasks in parameter tuning with surrogates model
            \begin{figure}
                \centering
                \includegraphics[width=\textwidth]{content/images/tax_mb_tuning.png}
                \caption[Phases and tasks within a generalized multi-objective parameter tuning]{Phases and tasks within a generalized multi-objective parameter tuning}
                \label{fig:mo_param_tuning}
            \end{figure}

            For extrapolate samples, there are two approaches established. 1) Direct build surrogates on scalarize objectives and produce a surrogate model as aggregation. In this case, the multi-objective problem transforms into a single-objective one. 2) Keep original dimensionality of the problem, and apply one or several models to hold and infer in objective space.
            The optimization search represents an exploration of the optimal point(s) with a surrogate model. This step produces candidates for a real evaluation. In the second stage, sorting and selection are carried out. The required number of points is allowed to estimate and update the sample set. The advantage of possible prediction several parameters instead of a single one is not only used for improving the exploration of the parameter space, but also for parallelizing evaluation.  Optimization iterations continue until the stop condition is satisfied.
    
    
            \paragraph{Compositional surrogates}
            The variability and extensibility are essential for configurable parameter tuning, such as a software product line. The optimization round is monolithic and context dependant. As shown in Figure \ref{fig:mo_param_tuning}, the potential to reuse components in a workflow is huge. The same single-objective models can be equally applied to various types of problems in multi-/single-objective optimization. The optimization algorithm weakly depends on the type of simulation. 
            Consider improving parameter tuning to multiply criteria on the fly by dynamically duplicate surrogate model or even create several variants surrogate hypothesis.

        % --------------------------------------------------------------------------------------------
        % ------------------------------------------------     Domain-specific Surrogate model      
        \subsection{Domain-specific problem}
        Intending to find the best solution with less effort, surrogate models are domain-specific. It could be an interpreter as a Non-free lunch theorem in model-based optimization. If we extend this argument, then the same optimization problem in different parameter tuning iteration could be interpreted as another optimization problem. This means that to reduce effort and increase the convergence of an algorithm, we should change the surrogate model depend on how much samples do we have. As one would expect, no approximation method is universal.
        This leads us to use a portfolio with surrogate models. On each optimization, iteration tries several models and selects thous who have the best accuracy. As a negative consequence, the model fitting additional introduces an additional overhead into the optimization.


        % --------------------------------------------------------------------------------------------
        % ------------------------------------------------     Build surrogate model     
        \subsection{Build the surrogate model(s). Sampling plan}
        Initial samples should provide maxim information to build a valuable model. With more samples, in case of proper fitting, the exact model is obtained, and in optimization, is reached better results. On the other hand, the initial sample size may be too big, and this is wasting samples. Furthermore, samples maybe not enough, and better select points from initial design than to be guided by an incorrect model.

        Given the type of objective surface, the expert can assume how much sample points are required to approximate the objective(s). For simple dependencies or more complex surfaces, the difference can be hundreds or thousands of points. In the case of the optimization black-box, this information is unknown. Therefore a dynamic sampling plan should be implemented to reduce the number of estimations and improve the convergence of the optimization algorithm.


        % --------------------------------------------------------------------------------------------
        % -------------------------------------------------------        Discussion       ------------
        \paragraph{Discussion}


        Example of each type of optimization. Justification solution.
        Conclusion: Design gap in optimization/parameter tuning. 
        Need to indicate optimization workflow for expensive process/experiments. 
        The argument(s) why we need a new architecture. Reference to composition architecture.




    % --------------------------------------------------------------------------------------------
    % ------------------------------                    Scope of work       
    \section{Scope of work}
        Surrogate based optimization has proven effective in many aspects of engineering and in applications where data is "expensive", or difficult, to evaluate.

        Describe and implement workflow for expensive multi-objective parameter tuning of the derivative-free, black-box system. The proposed solutions are backword compatable for single-criteria optimization. 
        Thre are follows research scope in this thesis:
        \begin{itemize}
            \item Single and compositional surrogate models for objectives
            \item The main optimization search technique selected a multi-objective evolutionary algorithm.
            \item Consider metrics for solution: hypervolume, space, and non-dominated ratio.
            \item Dynamic initial sampling
        \end{itemize}

        Goal:
        \begin{enumerate}
            \item Globally optimize an objective multi-objective function that is expensive to evaluate.
            \item Scalable multi-objective optimization
            \item Components reuse. Extensibility with other frameworks
        \end{enumerate}

        Problem:
        \begin{enumerate}
            \item A large number of the target black-box evaluations
            \item Surrogate selection
            \item Code duplication
        \end{enumerate}

        Solution:
        \begin{enumerate}
            \item Surrogate portfolio
            \item Compositional surrogate 
            \item Adaptive sampling plan
        \end{enumerate}


    % The single criterion in parameter tuning may not be sufficient to characterize the behavior of the configuration space correctly; Therefore, multiple criteria have to be considered.


    % This search-based software engineering is a rapidly expanding area of research and a full survey of that work is beyond the scope of this thesis.


    % % -------------------       Surrogate-model in MOEA       
    % \paragraph{Surrogate-model-based MOEA}

    % Surrogates are also used to rank and filter out offspring according to Pareto-related indicators like the hypervolume \cite{EmmerichGN06}, or a weighted sum of the objectives \cite{TaboadaBCW07}. The problem with the methods that use hypervolume as a way of finding promising solutions is the calculation time needed to calculate the hypervolume, especially on many objectives. Another possibility is described in \cite{Li2009}, where the authors present an algorithm that calculates only non-dominated solutions or solutions that can, because of variance, become non-dominated. 


    % % ------------------        Surrogate-model with MOEA       
    % \paragraph{Integration of the Surrogate Model}
    % Direct fitness replacement and indirect fitness replacement
    % Kind of extending the search stage of MOEA with surrogate to simulate evaluation of population. It transform the problem of searching a new better population to improving general hypothesis of how and where Pareto set presented.  

    % In surrogate-model-based multiobjective optimization, approximated values are often mistakenly used in the solution comparison. As a consequence, exactly evaluated good solutions can be discarded from the population because they appear to be dominated by the inaccurate and over-optimistic approximations. This can slow the optimization process or even prevent the algorithm from finding the best solutions \cite{MlakarPTF15}. 


    % General classification \cite{MlakarPTF15}:
    % Within surrogate-model-based optimization algorithms, a mechanism is needed to find a balance between the exact and approximate evaluations. In evolutionary algorithms, this mechanism is called evolution control \cite{Jin05} and can be either fixed or adaptive. In fixed evolution control the number of exact function evaluations that will be performed during the optimization is known in advance. Fixed evolution control can be further divided into generation-based control, where in some generations all solutions are approximated and in the others, they are exactly evaluated \cite{DebN07}, and individual based control, where in every generation some (usually the best) solutions are exactly evaluated and others approximated \cite{Grierson1993}. In adaptive evolution control, the number of exactly evaluated solutions is not known in advance but depends on the accuracy of the model for the given problem. Adaptive evolution control can be used in one of two ways: as a part of a memetic search or to pre-select the promising individuals which are then exactly evaluated \cite{PilatN12}.
